"""
Pipeline d'entra√Ænement pour les mod√®les YOLO et OCR
Ce module g√®re l'entra√Ænement, la validation et la sauvegarde des mod√®les.
"""

import logging
import os
import time
from pathlib import Path
from typing import Dict, Optional, Tuple
import yaml

import mlflow
import mlflow.pytorch
from ultralytics import YOLO
import torch
import numpy as np
from PIL import Image
import cv2

# Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class YOLOTrainingPipeline:
    """Pipeline d'entra√Ænement pour le mod√®le YOLO de d√©tection de panneaux"""
    
    def __init__(self, config_path: str = "conf/base/model_config.yml"):
        """
        Initialise le pipeline d'entra√Ænement YOLO
        
        Args:
            config_path: Chemin vers le fichier de configuration
        """
        self.config = self._load_config(config_path)
        self.yolo_config = self.config['yolo']
        self.data_config = self.config['data']
        
        # Configuration MLflow
        mlflow.set_experiment("RoadSign_Detection_YOLOv8")
        
        # Pr√©paration des chemins
        self.data_yaml_path = None
        self.model = None
        
    def _load_config(self, config_path: str) -> Dict:
        """Charge la configuration depuis le fichier YAML"""
        try:
            with open(config_path, 'r', encoding='utf-8') as file:
                return yaml.safe_load(file)
        except FileNotFoundError:
            logger.error(f"Fichier de configuration non trouv√©: {config_path}")
            raise
    
    def prepare_dataset_config(self) -> str:
        """
        Pr√©pare le fichier de configuration YOLO dataset
        
        Returns:
            str: Chemin vers le fichier dataset.yaml cr√©√©
        """
        dataset_config = {
            'path': str(Path.cwd() / 'data' / '02_processed'),
            'train': 'train/images',
            'val': 'val/images',
            'test': 'test/images',
            'nc': self.data_config['dataset']['classes'],  # Nombre de classes
            'names': self._get_class_names()
        }
        
        dataset_yaml_path = Path('data/02_processed/dataset.yaml')
        with open(dataset_yaml_path, 'w') as f:
            yaml.dump(dataset_config, f, default_flow_style=False)
        
        logger.info(f"Configuration dataset YOLO cr√©√©e: {dataset_yaml_path}")
        return str(dataset_yaml_path)
    
    def _get_class_names(self) -> list:
        """Retourne la liste des noms de classes"""
        # Pour l'exemple, utilisons les classes GTSRB simplifi√©es
        return [
            "Speed limit (20km/h)", "Speed limit (30km/h)", "Speed limit (50km/h)",
            "Speed limit (60km/h)", "Speed limit (70km/h)", "Speed limit (80km/h)",
            "End of speed limit (80km/h)", "Speed limit (100km/h)", "Speed limit (120km/h)",
            "No passing", "No passing veh over 3.5 tons", "Right-of-way at intersection",
            "Priority road", "Yield", "Stop", "No vehicles", "Veh > 3.5 tons prohibited",
            "No entry", "General caution", "Dangerous curve left", "Dangerous curve right",
            "Double curve", "Bumpy road", "Slippery road", "Road narrows on the right",
            "Road work", "Traffic signals", "Pedestrians", "Children crossing",
            "Bicycles crossing", "Beware of ice/snow", "Wild animals crossing",
            "End speed + passing limits", "Turn right ahead", "Turn left ahead",
            "Ahead only", "Go straight or right", "Go straight or left",
            "Keep right", "Keep left", "Roundabout mandatory", "End of no passing",
            "End no passing veh > 3.5 tons"
        ]
    
    def initialize_model(self) -> YOLO:
        """
        Initialise le mod√®le YOLO
        
        Returns:
            YOLO: Mod√®le YOLO initialis√©
        """
        model_config = self.yolo_config['model']
        architecture = model_config['architecture']
        pretrained = model_config['pretrained']
        
        if pretrained:
            # Charge un mod√®le pr√©-entra√Æn√©
            model = YOLO(f"{architecture}.pt")
            logger.info(f"Mod√®le {architecture} pr√©-entra√Æn√© charg√©")
        else:
            # Cr√©e un nouveau mod√®le depuis la config
            model = YOLO(f"{architecture}.yaml")
            logger.info(f"Nouveau mod√®le {architecture} cr√©√©")
        
        return model
    
    def train_model(self, resume: bool = False) -> Dict[str, float]:
        """
        Entra√Æne le mod√®le YOLO
        
        Args:
            resume: Reprendre un entra√Ænement pr√©c√©dent
            
        Returns:
            Dict[str, float]: M√©triques d'entra√Ænement
        """
        with mlflow.start_run(run_name=f"yolo_training_{int(time.time())}"):
            try:
                logger.info("=== D√âBUT DE L'ENTRA√éNEMENT YOLO ===")
                
                # Pr√©paration dataset
                self.data_yaml_path = self.prepare_dataset_config()
                
                # Initialisation mod√®le
                self.model = self.initialize_model()
                
                # Configuration d'entra√Ænement
                training_config = self.yolo_config['training']
                
                # Log des param√®tres MLflow
                mlflow.log_params({
                    "architecture": self.yolo_config['model']['architecture'],
                    "epochs": training_config['epochs'],
                    "batch_size": training_config['batch_size'],
                    "img_size": training_config['img_size'],
                    "lr0": training_config['lr0'],
                    "optimizer": training_config['optimizer'],
                    "augment": training_config['augment']
                })
                
                # Entra√Ænement
                logger.info("D√©marrage de l'entra√Ænement...")
                results = self.model.train(
                    data=self.data_yaml_path,
                    epochs=training_config['epochs'],
                    batch=training_config['batch_size'],
                    imgsz=training_config['img_size'],
                    lr0=training_config['lr0'],
                    lrf=training_config['lrf'],
                    momentum=training_config['momentum'],
                    weight_decay=training_config['weight_decay'],
                    warmup_epochs=training_config['warmup_epochs'],
                    warmup_momentum=training_config['warmup_momentum'],
                    warmup_bias_lr=training_config['warmup_bias_lr'],
                    degrees=training_config['degrees'],
                    translate=training_config['translate'],
                    scale=training_config['scale'],
                    shear=training_config['shear'],
                    perspective=training_config['perspective'],
                    flipud=training_config['flipud'],
                    fliplr=training_config['fliplr'],
                    mosaic=training_config['mosaic'],
                    mixup=training_config['mixup'],
                    save_period=training_config.get('save_period', 10),
                    resume=resume,
                    device=0 if torch.cuda.is_available() else 'cpu'
                )
                
                # Extraction des m√©triques finales
                metrics = self._extract_training_metrics(results)
                
                # Log des m√©triques MLflow
                for metric_name, metric_value in metrics.items():
                    mlflow.log_metric(metric_name, metric_value)
                
                # Sauvegarde du mod√®le
                model_path = self._save_model()
                mlflow.log_artifact(model_path, "models")
                
                # Log des courbes d'entra√Ænement
                self._log_training_plots()
                
                logger.info("=== ENTRA√éNEMENT YOLO TERMIN√â ===")
                logger.info(f"M√©triques finales: {metrics}")
                
                return metrics
                
            except Exception as e:
                logger.error(f"Erreur durant l'entra√Ænement: {e}")
                mlflow.log_param("error_message", str(e))
                raise
    
    def _extract_training_metrics(self, results) -> Dict[str, float]:
        """Extrait les m√©triques d'entra√Ænement"""
        try:
            # Les r√©sultats YOLO contiennent les m√©triques dans results.results_dict
            if hasattr(results, 'results_dict'):
                metrics_dict = results.results_dict
            else:
                # Fallback: utiliser les m√©triques du mod√®le
                metrics_dict = self.model.metrics
            
            # Extraction des m√©triques principales
            metrics = {
                'map50': float(metrics_dict.get('metrics/mAP50(B)', 0.0)),
                'map50_95': float(metrics_dict.get('metrics/mAP50-95(B)', 0.0)),
                'precision': float(metrics_dict.get('metrics/precision(B)', 0.0)),
                'recall': float(metrics_dict.get('metrics/recall(B)', 0.0)),
                'train_loss': float(metrics_dict.get('train/box_loss', 0.0)),
                'val_loss': float(metrics_dict.get('val/box_loss', 0.0))
            }
            
            # Calcul F1-score si pr√©cision et rappel disponibles
            if metrics['precision'] > 0 and metrics['recall'] > 0:
                metrics['f1_score'] = 2 * (metrics['precision'] * metrics['recall']) / (metrics['precision'] + metrics['recall'])
            
            return metrics
            
        except Exception as e:
            logger.warning(f"Impossible d'extraire toutes les m√©triques: {e}")
            return {
                'map50': 0.0,
                'map50_95': 0.0,
                'precision': 0.0,
                'recall': 0.0,
                'f1_score': 0.0
            }
    
    def _save_model(self) -> str:
        """Sauvegarde le mod√®le entra√Æn√©"""
        models_dir = Path("data/04_models")
        models_dir.mkdir(exist_ok=True)
        
        timestamp = int(time.time())
        model_name = f"yolo_road_signs_{timestamp}.pt"
        model_path = models_dir / model_name
        
        # Sauvegarde du mod√®le
        self.model.save(str(model_path))
        
        # Sauvegarde √©galement au format ONNX pour l'inf√©rence
        onnx_path = models_dir / f"yolo_road_signs_{timestamp}.onnx"
        self.model.export(format='onnx', save_dir=str(models_dir))
        
        logger.info(f"Mod√®le sauvegard√©: {model_path}")
        logger.info(f"Mod√®le ONNX sauvegard√©: {onnx_path}")
        
        return str(model_path)
    
    def _log_training_plots(self):
        """Log les graphiques d'entra√Ænement dans MLflow"""
        try:
            # Les plots YOLO sont g√©n√©ralement sauv√©s dans runs/detect/train
            runs_dir = Path("runs/detect")
            if runs_dir.exists():
                latest_run = max(runs_dir.iterdir(), key=os.path.getctime)
                
                # Log des plots s'ils existent
                plots_to_log = [
                    "results.png", "confusion_matrix.png", 
                    "F1_curve.png", "P_curve.png", "R_curve.png", "PR_curve.png"
                ]
                
                for plot_name in plots_to_log:
                    plot_path = latest_run / plot_name
                    if plot_path.exists():
                        mlflow.log_artifact(str(plot_path), "training_plots")
                        logger.info(f"Plot logg√©: {plot_name}")
        
        except Exception as e:
            logger.warning(f"Impossible de logger les plots: {e}")
    
    def validate_model(self) -> Dict[str, float]:
        """
        Valide le mod√®le sur le set de validation
        
        Returns:
            Dict[str, float]: M√©triques de validation
        """
        if not self.model:
            raise ValueError("Mod√®le non initialis√©. Entra√Æner d'abord le mod√®le.")
        
        logger.info("Validation du mod√®le...")
        
        # Validation YOLO
        results = self.model.val(data=self.data_yaml_path)
        
        # Extraction des m√©triques
        metrics = self._extract_training_metrics(results)
        
        logger.info(f"M√©triques de validation: {metrics}")
        return metrics


class OCRTrainingPipeline:
    """Pipeline de configuration et optimisation OCR"""
    
    def __init__(self, config_path: str = "conf/base/model_config.yml"):
        """
        Initialise le pipeline OCR
        
        Args:
            config_path: Chemin vers le fichier de configuration
        """
        self.config = self._load_config(config_path)
        self.ocr_config = self.config['ocr']
        
        # Configuration MLflow
        mlflow.set_experiment("RoadSign_OCR_Recognition")
    
    def _load_config(self, config_path: str) -> Dict:
        """Charge la configuration depuis le fichier YAML"""
        try:
            with open(config_path, 'r', encoding='utf-8') as file:
                return yaml.safe_load(file)
        except FileNotFoundError:
            logger.error(f"Fichier de configuration non trouv√©: {config_path}")
            raise
    
    def setup_tesseract(self) -> bool:
        """
        Configure Tesseract OCR
        
        Returns:
            bool: True si succ√®s, False sinon
        """
        with mlflow.start_run(run_name="tesseract_setup"):
            try:
                import pytesseract
                
                # Test de Tesseract
                version = pytesseract.get_tesseract_version()
                logger.info(f"Tesseract version: {version}")
                
                # Configuration Tesseract
                tesseract_config = self.ocr_config['tesseract']
                
                # Log des param√®tres
                mlflow.log_param("tesseract_version", str(version))
                mlflow.log_param("languages", tesseract_config['lang'])
                mlflow.log_param("config", tesseract_config['config'])
                
                # Test OCR sur une image d'exemple
                test_accuracy = self._test_ocr_accuracy()
                mlflow.log_metric("test_accuracy", test_accuracy)
                
                logger.info("Tesseract configur√© avec succ√®s")
                return True
                
            except Exception as e:
                logger.error(f"Erreur configuration Tesseract: {e}")
                mlflow.log_param("error_message", str(e))
                return False
    
    def _test_ocr_accuracy(self) -> float:
        """Test la pr√©cision OCR sur des images d'exemple"""
        try:
            import pytesseract
            
            # Cr√©ation d'une image de test simple
            test_image = np.ones((100, 300, 3), dtype=np.uint8) * 255
            cv2.putText(test_image, "STOP", (50, 60), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 0), 3)
            
            # OCR
            config = self.ocr_config['tesseract']['config']
            text = pytesseract.image_to_string(test_image, config=config).strip()
            
            # Test de pr√©cision simple
            expected = "STOP"
            accuracy = 1.0 if text.upper() == expected else 0.0
            
            logger.info(f"Test OCR - Attendu: '{expected}', Obtenu: '{text}', Pr√©cision: {accuracy}")
            return accuracy
            
        except Exception as e:
            logger.warning(f"Impossible de tester l'OCR: {e}")
            return 0.0
    
    def optimize_preprocessing(self) -> Dict[str, float]:
        """
        Optimise les param√®tres de preprocessing pour l'OCR
        
        Returns:
            Dict[str, float]: M√©triques d'optimisation
        """
        with mlflow.start_run(run_name="ocr_preprocessing_optimization"):
            logger.info("Optimisation du preprocessing OCR...")
            
            # Test de diff√©rents param√®tres de preprocessing
            preprocessing_configs = [
                {"denoise": True, "contrast": 1.5, "brightness": 10},
                {"denoise": False, "contrast": 2.0, "brightness": 0},
                {"denoise": True, "contrast": 1.2, "brightness": 5}
            ]
            
            best_config = None
            best_score = 0.0
            
            for i, config in enumerate(preprocessing_configs):
                score = self._test_preprocessing_config(config)
                mlflow.log_metric(f"config_{i}_score", score)
                mlflow.log_params({f"config_{i}_{k}": v for k, v in config.items()})
                
                if score > best_score:
                    best_score = score
                    best_config = config
            
            # Log de la meilleure configuration
            mlflow.log_params({f"best_{k}": v for k, v in best_config.items()})
            mlflow.log_metric("best_score", best_score)
            
            logger.info(f"Meilleure configuration: {best_config} (score: {best_score})")
            return {"best_score": best_score, "config": best_config}
    
    def _test_preprocessing_config(self, config: Dict) -> float:
        """Teste une configuration de preprocessing"""
        try:
            # Simulation d'un test de preprocessing
            # En production, cela testerait sur un dataset r√©el
            base_score = 0.7
            
            # Bonus/malus selon la configuration
            score_modifier = 0.0
            if config.get("denoise", False):
                score_modifier += 0.1
            if 1.0 <= config.get("contrast", 1.0) <= 2.0:
                score_modifier += 0.1
            if -10 <= config.get("brightness", 0) <= 20:
                score_modifier += 0.05
            
            return min(1.0, base_score + score_modifier)
            
        except Exception:
            return 0.0


def main():
    """Point d'entr√©e principal du pipeline d'entra√Ænement"""
    try:
        logger.info("üöÄ === D√âBUT DU PIPELINE D'ENTRA√éNEMENT ===")
        
        # 1. Entra√Ænement YOLO
        logger.info("üìç √âTAPE 1: Entra√Ænement YOLO")
        yolo_pipeline = YOLOTrainingPipeline()
        yolo_metrics = yolo_pipeline.train_model()
        
        # 2. Configuration OCR  
        logger.info("üìç √âTAPE 2: Configuration OCR")
        ocr_pipeline = OCRTrainingPipeline()
        ocr_setup_success = ocr_pipeline.setup_tesseract()
        
        if ocr_setup_success:
            ocr_metrics = ocr_pipeline.optimize_preprocessing()
        else:
            ocr_metrics = {"best_score": 0.0}
        
        # 3. Validation crois√©e
        logger.info("üìç √âTAPE 3: Validation finale")
        validation_metrics = yolo_pipeline.validate_model()
        
        # R√©sum√© final
        final_results = {
            "yolo_training": yolo_metrics,
            "ocr_optimization": ocr_metrics,
            "validation": validation_metrics
        }
        
        print("\n" + "="*60)
        print("‚úÖ ENTRA√éNEMENT TERMIN√â AVEC SUCC√àS!")
        print("="*60)
        print(f"üìä YOLO mAP@50: {yolo_metrics.get('map50', 0.0):.3f}")
        print(f"üìä YOLO Pr√©cision: {yolo_metrics.get('precision', 0.0):.3f}")
        print(f"üìä YOLO Rappel: {yolo_metrics.get('recall', 0.0):.3f}")
        print(f"üìä OCR Score: {ocr_metrics.get('best_score', 0.0):.3f}")
        print("="*60)
        
        return final_results
        
    except Exception as e:
        logger.error(f"‚ùå Erreur dans le pipeline d'entra√Ænement: {e}")
        raise


if __name__ == "__main__":
    main()
