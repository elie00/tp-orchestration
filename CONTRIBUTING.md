# ğŸ¤ Guide de Contribution - Road Sign ML Project

Merci de contribuer au **Road Sign ML Project** ! Ce guide dÃ©crit les bonnes pratiques pour dÃ©velopper, tester et dÃ©ployer le projet de maniÃ¨re collaborative.

---

## ğŸ¯ **AperÃ§u du Projet**

Ce projet implÃ©mente un systÃ¨me ML de dÃ©tection de panneaux routiers avec :
- **ML Pipeline** : YOLOv8 + OCR Tesseract
- **API Production** : FastAPI + interface web
- **Infrastructure** : Kubernetes + MLflow + monitoring

---

## ğŸš€ **DÃ©marrage Rapide**

### **Setup Initial**
```bash
# 1. Fork et clone
git clone https://github.com/elie00/tp-orchestration.git
cd tp-orchestration

# 2. Configuration environnement
python3.10 -m venv .venv
source .venv/bin/activate
pip install -r requirements/dev.txt

# 3. Tests de validation
pytest src/tests/ -v
python3.10 src/api/main.py

# 4. VÃ©rification
curl http://localhost:8000/health
```

---

## ğŸŒ³ **Workflow Git**

### **ModÃ¨le de Branches**
```
main          â† Production (tags v1.0.0, v1.1.0...)
â”œâ”€â”€ develop   â† IntÃ©gration (dÃ©ploiement staging auto)
â”‚   â”œâ”€â”€ feature/nouvelle-detection
â”‚   â”œâ”€â”€ feature/api-v2
â”‚   â””â”€â”€ hotfix/security-patch
```

### **CrÃ©ation de FonctionnalitÃ©**
```bash
# 1. Partir de develop
git checkout develop
git pull origin develop

# 2. CrÃ©er une branche feature
git checkout -b feature/description-courte

# 3. DÃ©velopper avec commits atomiques
git add .
git commit -m "feat: Description de la fonctionnalitÃ©"

# 4. Push et Pull Request
git push origin feature/description-courte
# CrÃ©er PR vers develop sur GitHub
```

### **Types de Branches**
- **`feature/`** : Nouvelles fonctionnalitÃ©s
- **`bugfix/`** : Corrections de bugs
- **`hotfix/`** : Corrections urgentes
- **`refactor/`** : Refactoring sans nouvelle fonctionnalitÃ©
- **`docs/`** : Documentation uniquement

---

## ğŸ“ **Standards de Code**

### **Messages de Commit (Conventional Commits)**
```bash
# Types autorisÃ©s :
feat:     # Nouvelle fonctionnalitÃ©
fix:      # Correction de bug
docs:     # Documentation
style:    # Format, pas de changement de logique
refactor: # Refactoring
test:     # Ajout de tests
chore:    # Maintenance, dÃ©pendances

# Exemples :
git commit -m "feat: Ajouter support panneaux europÃ©ens"
git commit -m "fix: Corriger detection YOLO avec petites images"
git commit -m "docs: Mettre Ã  jour guide API"
git commit -m "test: Ajouter tests pipeline OCR"
```

### **Format du Code**
```bash
# Formater automatiquement avant commit
black src/ --line-length 88
isort src/ --profile black

# Linting
flake8 src/ --max-line-length=88 --extend-ignore=E203,W503

# Type checking (optionnel)
mypy src/ --ignore-missing-imports
```

### **Standards Python**
- **Style** : PEP 8 + Black formatting
- **Docstrings** : Google style
- **Type Hints** : EncouragÃ©s pour les fonctions publiques
- **Imports** : isort avec profil black

---

## ğŸ§ª **Tests et QualitÃ©**

### **Exigences de Tests**
- **Coverage minimum** : 80%
- **Tests unitaires** : Chaque nouvelle fonction
- **Tests d'intÃ©gration** : Chaque nouveau endpoint API
- **Tests E2E** : Chaque nouveau pipeline ML

### **ExÃ©cution des Tests**
```bash
# Tests complets avec coverage
pytest src/tests/ -v --cov=src --cov-report=html

# Tests spÃ©cifiques
pytest src/tests/test_api.py::test_health_endpoint -v

# Tests en mode watch (dÃ©veloppement)
pytest-watch src/tests/

# Coverage report
open htmlcov/index.html
```

### **Ã‰criture de Tests**
```python
# Exemple de test unitaire
def test_yolo_detection():
    """Test de dÃ©tection YOLO avec image de test."""
    from src.ml_pipelines.inference_pipeline import InferencePipeline
    
    pipeline = InferencePipeline()
    result = pipeline.detect_objects("test_images/stop_sign.jpg")
    
    assert result is not None
    assert len(result["detections"]) > 0
    assert result["detections"][0]["class"] == "stop_sign"

# Exemple de test API
def test_predict_endpoint(client):
    """Test endpoint de prÃ©diction."""
    with open("test_images/stop_sign.jpg", "rb") as f:
        response = client.post(
            "/predict",
            files={"file": ("test.jpg", f, "image/jpeg")}
        )
    
    assert response.status_code == 200
    data = response.json()
    assert "predictions" in data
```

---

## ğŸ—ï¸ **DÃ©veloppement par Composant**

### **API FastAPI**
```bash
# Structure des endpoints
src/api/
â”œâ”€â”€ main.py              # Point d'entrÃ©e
â”œâ”€â”€ routes/
â”‚   â”œâ”€â”€ predict.py       # Endpoints ML
â”‚   â”œâ”€â”€ health.py        # Health checks
â”‚   â””â”€â”€ monitoring.py    # MÃ©triques
â””â”€â”€ services/
    â”œâ”€â”€ ml_service.py    # Logique ML
    â””â”€â”€ image_service.py # Traitement images
```

**Ajouter un endpoint :**
1. CrÃ©er la route dans `src/api/routes/`
2. Ajouter les tests dans `src/tests/test_api.py`
3. Documenter avec docstrings FastAPI
4. Tester manuellement avec Swagger UI

### **Pipeline ML**
```bash
# Structure des pipelines
src/ml_pipelines/
â”œâ”€â”€ data_pipeline.py      # Ingestion donnÃ©es
â”œâ”€â”€ training_pipeline.py  # EntraÃ®nement modÃ¨les
â”œâ”€â”€ inference_pipeline.py # PrÃ©dictions
â””â”€â”€ evaluation_pipeline.py # MÃ©triques
```

**Ajouter un pipeline :**
1. CrÃ©er la classe dans `src/ml_pipelines/`
2. IntÃ©grer tracking MLflow
3. Ajouter tests unitaires
4. Documenter paramÃ¨tres et outputs

### **Configuration**
```bash
# Configuration centralisÃ©e
conf/base/
â”œâ”€â”€ model_config.yml    # ParamÃ¨tres ML
â”œâ”€â”€ mlflow_config.yml   # Configuration MLflow
â””â”€â”€ logging.yml         # Logs
```

**Modifier configuration :**
1. Mettre Ã  jour le fichier YAML
2. Valider avec schema si disponible
3. Tester impact sur tests existants
4. Documenter changements

---

## ğŸ³ **Docker et DÃ©ploiement**

### **Images Docker**
```bash
# Build local pour tests
docker build -f docker/Dockerfile.api -t road-sign-api:dev .

# Test de l'image
docker run -p 8000:8000 road-sign-api:dev

# Push vers registry (automatique via CI/CD)
```

### **Docker Compose**
```bash
# Stack de dÃ©veloppement complÃ¨te
docker-compose up -d

# Services disponibles :
# - API : http://localhost:8000
# - MLflow : http://localhost:5000
# - Grafana : http://localhost:3000
# - Prometheus : http://localhost:9090

# Logs
docker-compose logs -f api
```

### **Kubernetes**
```bash
# Test local avec minikube
minikube start
kubectl apply -f kubernetes/staging/

# VÃ©rification
kubectl get pods -n road-sign-ml-staging
kubectl port-forward svc/road-sign-api 8000:80 -n road-sign-ml-staging
```

---

## ğŸ“Š **MLflow et ExpÃ©rimentations**

### **Tracking des ExpÃ©rimentations**
```python
import mlflow

# Dans un pipeline ML
with mlflow.start_run(run_name="experiment_name"):
    # Log paramÃ¨tres
    mlflow.log_params({
        "learning_rate": 0.01,
        "batch_size": 32
    })
    
    # Log mÃ©triques
    mlflow.log_metrics({
        "accuracy": 0.95,
        "mAP": 0.87
    })
    
    # Log modÃ¨le
    mlflow.sklearn.log_model(model, "model")
```

### **Registre de ModÃ¨les**
```python
# Enregistrer un modÃ¨le
mlflow.register_model(
    model_uri="runs:/12345/model",
    name="road_sign_yolo"
)

# Promouvoir vers production
client = MlflowClient()
client.transition_model_version_stage(
    name="road_sign_yolo",
    version=1,
    stage="Production"
)
```

---

## ğŸ” **Review et Validation**

### **Checklist Pull Request**

#### **Code Quality âœ…**
- [ ] Code formatÃ© avec Black + isort
- [ ] Linting flake8 sans erreurs
- [ ] Type hints ajoutÃ©s (recommandÃ©)
- [ ] Docstrings pour fonctions publiques

#### **Tests âœ…**
- [ ] Tests unitaires ajoutÃ©s
- [ ] Coverage â‰¥ 80% maintenu
- [ ] Tests existants passent
- [ ] Tests E2E si nÃ©cessaire

#### **Documentation âœ…**
- [ ] README mis Ã  jour si nÃ©cessaire
- [ ] Docstrings API mises Ã  jour
- [ ] Changelog mis Ã  jour
- [ ] Comments dans le code complexe

#### **SÃ©curitÃ© âœ…**
- [ ] Pas de secrets hardcodÃ©s
- [ ] Validation des inputs utilisateur
- [ ] Gestion d'erreurs appropriÃ©e
- [ ] Logs appropriÃ©s (pas de donnÃ©es sensibles)

#### **Performance âœ…**
- [ ] Pas de rÃ©gression de performance
- [ ] Optimisations si nÃ©cessaire
- [ ] Tests de charge si impact attendu

### **Processus de Review**
1. **Auto-checks** : CI/CD exÃ©cute tests automatiquement
2. **Review par les pairs** : Au moins 1 approbation
3. **Tests manuels** : VÃ©rifier fonctionnalitÃ©
4. **Security check** : Scan automatique des vulnÃ©rabilitÃ©s

---

## ğŸš€ **DÃ©ploiement**

### **Environnements**

#### **Development** (Local)
- **URL** : http://localhost:8000
- **MLflow** : http://localhost:5000
- **Auto-deploy** : Manuel

#### **Staging** (Auto-deploy)
- **URL** : https://staging-api.road-sign-ml.com
- **Trigger** : Push sur `develop`
- **Tests** : Automatiques + manuels

#### **Production** (Approval required)
- **URL** : https://api.road-sign-ml.com
- **Trigger** : Tag `v*.*.*`
- **Approval** : 1+ reviewer requis

### **Processus de Release**
```bash
# 1. Merge develop vers main
git checkout main
git merge develop
git push origin main

# 2. CrÃ©er tag de version
git tag v1.2.0
git push origin v1.2.0

# 3. GitHub Actions dÃ©clenche dÃ©ploiement production
# 4. Approbation manuelle requise
# 5. DÃ©ploiement automatique aprÃ¨s approbation
```

---

## ğŸ“ˆ **Monitoring et Debugging**

### **Logs**
```bash
# Logs locaux
tail -f logs/app.log

# Logs Kubernetes
kubectl logs -f deployment/road-sign-api -n road-sign-ml-prod

# Logs centralisÃ©s (Grafana)
# AccÃ©der Ã  Grafana â†’ Explore â†’ Loki
```

### **MÃ©triques**
- **API** : Response time, error rate, throughput
- **ML** : Inference time, model accuracy, cache hit rate
- **Infrastructure** : CPU, memory, disk usage

### **Alertes**
- **Critical** : API down, error rate > 10%
- **Warning** : Response time > 5s, memory > 80%
- **Info** : DÃ©ploiement rÃ©ussi, nouveau modÃ¨le

---

## ğŸ†˜ **Support et Aide**

### **ProblÃ¨mes Courants**

#### **Tests qui Ã©chouent**
```bash
# Nettoyer cache
pytest --cache-clear
rm -rf .pytest_cache/

# RÃ©installer dÃ©pendances
pip install -r requirements/dev.txt --force-reinstall

# Debug mode
pytest -v -s --tb=long
```

#### **API ne dÃ©marre pas**
```bash
# VÃ©rifier port disponible
lsof -i :8000

# VÃ©rifier dÃ©pendances
pip check

# Mode debug
python3.10 src/api/main.py --debug
```

#### **MLflow connection error**
```bash
# DÃ©marrer MLflow server
mlflow server --host 0.0.0.0 --port 5000

# VÃ©rifier configuration
cat conf/base/mlflow_config.yml
```

### **OÃ¹ Demander de l'Aide**
1. **Documentation** : README.md, docs/
2. **Issues GitHub** : https://github.com/elie00/tp-orchestration/issues
3. **Discussions** : GitHub Discussions
4. **Slack** : #road-sign-ml (si configurÃ©)

---

## ğŸ† **Best Practices**

### **DÃ©veloppement**
- **Commits frÃ©quents** : Petits commits atomiques
- **Tests first** : Ã‰crire tests avant fonctionnalitÃ©
- **Documentation** : Code self-documented + comments
- **Performance** : Profiler avant optimiser

### **Collaboration**
- **Communication** : Commenter les PRs
- **Reviews constructives** : Suggestions, pas juste critiques
- **Partage de connaissances** : Documentation Ã  jour

### **DÃ©ploiement**
- **Gradual rollout** : Staging â†’ Production
- **Monitoring** : VÃ©rifier mÃ©triques post-deploy
- **Rollback plan** : Toujours prÃªt Ã  revenir en arriÃ¨re

---

## ğŸ“ **Contact**

- **Maintainer** : [elie00](https://github.com/elie00) - elieyvon.b.o@gmail.com
- **Issues** : https://github.com/elie00/tp-orchestration/issues
- **Discussions** : https://github.com/elie00/tp-orchestration/discussions

---

**ğŸ‰ Merci de contribuer au Road Sign ML Project ! ğŸš¦**

*Ensemble, construisons le meilleur systÃ¨me de dÃ©tection de panneaux routiers !*
